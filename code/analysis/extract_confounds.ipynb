{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists, join, splitext\n",
    "from os import makedirs\n",
    "import json\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import os\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copied from sam nastase's extract confounds script ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for extracting aCompCor components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_compcor(confounds_df, confounds_meta,\n",
    "                    n_comps=5, method='tCompCor',\n",
    "                    tissue=None):\n",
    "\n",
    "    # Check that we sensible number of components\n",
    "    assert n_comps > 0\n",
    "\n",
    "    # Check that method is specified correctly\n",
    "    assert method in ['aCompCor', 'tCompCor']\n",
    "\n",
    "    # Check that tissue is specified for aCompCor\n",
    "    if method == 'aCompCor' and tissue not in ['combined', 'CSF', 'WM']:\n",
    "        raise AssertionError(\"Must specify a tissue type \"\n",
    "                             \"(combined, CSF, or WM) for aCompCor\")\n",
    "\n",
    "    # Ignore tissue if specified for tCompCor\n",
    "    if method == 'tCompCor' and tissue:\n",
    "        print(\"Warning: tCompCor is not restricted to a tissue \"\n",
    "              f\"mask - ignoring tissue specification ({tissue})\")\n",
    "        tissue = None\n",
    "\n",
    "    # Get CompCor metadata for relevant method\n",
    "    compcor_meta = {c: confounds_meta[c] for c in confounds_meta\n",
    "                    if confounds_meta[c]['Method'] == method\n",
    "                    and confounds_meta[c]['Retained']}\n",
    "\n",
    "    # If aCompCor, filter metadata for tissue mask\n",
    "    if method == 'aCompCor':\n",
    "        compcor_meta = {c: compcor_meta[c] for c in compcor_meta\n",
    "                        if compcor_meta[c]['Mask'] == tissue}\n",
    "\n",
    "    # Make sure metadata components are sorted properly\n",
    "    comp_sorted = natsorted(compcor_meta)\n",
    "    for i, comp in enumerate(comp_sorted):\n",
    "        if comp != comp_sorted[-1]:\n",
    "            comp_next = comp_sorted[i + 1]\n",
    "            assert (compcor_meta[comp]['SingularValue'] >\n",
    "                    compcor_meta[comp_next]['SingularValue'])\n",
    "\n",
    "    # Either get top n components\n",
    "    if n_comps >= 1.0:\n",
    "        n_comps = int(n_comps)\n",
    "        if len(comp_sorted) >= n_comps:\n",
    "            comp_selector = comp_sorted[:n_comps]\n",
    "        else:\n",
    "            comp_selector = comp_sorted\n",
    "            print(f\"Warning: Only {len(comp_sorted)} {method} \"\n",
    "                  f\"components available ({n_comps} requested)\")\n",
    "\n",
    "    # Or components necessary to capture n proportion of variance\n",
    "    else:\n",
    "        comp_selector = []\n",
    "        for comp in comp_sorted:\n",
    "            comp_selector.append(comp)\n",
    "            if (compcor_meta[comp]['CumulativeVarianceExplained']\n",
    "                > n_comps):\n",
    "                break\n",
    "\n",
    "    # Check we didn't end up with degenerate 0 components\n",
    "    assert len(comp_selector) > 0\n",
    "\n",
    "    # Grab the actual component time series\n",
    "    confounds_compcor = confounds_df[comp_selector]\n",
    "    return confounds_compcor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for extracting group of (variable number) confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_group(confounds_df, groups):\n",
    "    \n",
    "    # Expect list, so change if string\n",
    "    if type(groups) == str:\n",
    "        groups = [groups]\n",
    "    \n",
    "    # Filter for all columns with label\n",
    "    confounds_group = []\n",
    "    for group in groups:\n",
    "        group_cols = [col for col in confounds_df.columns\n",
    "                      if group in col]\n",
    "        confounds_group.append(confounds_df[group_cols])\n",
    "    confounds_group = pd.concat(confounds_group, axis=1)\n",
    "    \n",
    "    return confounds_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading in confounds files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_confounds(confounds_fn):\n",
    "\n",
    "    # Load the confounds TSV files\n",
    "    confounds_df = pd.read_csv(confounds_fn, sep='\\t')\n",
    "\n",
    "    # Load the JSON sidecar metadata\n",
    "    with open(splitext(confounds_fn)[0] + '.json') as f:\n",
    "        confounds_meta = json.load(f)\n",
    "    return confounds_df, confounds_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_confounds(confounds_fn):\n",
    "\n",
    "    # Load the confounds TSV files\n",
    "    confounds_df = pd.read_csv(confounds_fn +\".tsv\", sep='\\t')\n",
    "\n",
    "    # Load the JSON sidecar metadata\n",
    "    with open(confounds_fn + '.json') as f:\n",
    "        confounds_meta = json.load(f)\n",
    "    return confounds_df, confounds_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for extracting confounds (including CompCor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_confounds(confounds_df, confounds_meta, model_spec):\n",
    "\n",
    "    # Pop out confound groups of variable number\n",
    "    groups = set(model_spec['confounds']).intersection(\n",
    "                    ['cosine', 'motion_outlier'])\n",
    "\n",
    "    # Grab the requested confounds\n",
    "    confounds = confounds_df[[c for c in model_spec['confounds']\n",
    "                              if c not in groups]]\n",
    "    \n",
    "    # Grab confound groups if present\n",
    "    if groups:\n",
    "        confounds_group = extract_group(confounds_df,\n",
    "                                        groups)\n",
    "        confounds = pd.concat([confounds, confounds_group],\n",
    "                              axis=1)\n",
    "\n",
    "    # Get aCompCor / tCompCor confounds if requested\n",
    "    compcors = set(model_spec).intersection(\n",
    "                    ['aCompCor', 'tCompCor'])\n",
    "    if compcors:\n",
    "        for compcor in compcors:\n",
    "            if type(model_spec[compcor]) == dict:\n",
    "                model_spec[compcor] = [model_spec[compcor]]\n",
    "            for compcor_kws in model_spec[compcor]:\n",
    "                confounds_compcor = extract_compcor(\n",
    "                    confounds_df,\n",
    "                    confounds_meta,\n",
    "                    method=compcor,\n",
    "                    **compcor_kws)\n",
    "                confounds = pd.concat([confounds,\n",
    "                                       confounds_compcor],\n",
    "                                      axis=1)\n",
    "    return confounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/jukebox/graziano/coolCatIsaac/MEI'\n",
    "data_dir = top_dir + \"/data\"\n",
    "behav_dir = data_dir + '/behavioral'\n",
    "rois_dir = data_dir + \"/rois\"\n",
    "fmri_prep = data_dir + '/bids/derivatives/fmriprep'\n",
    "work_dir = data_dir + '/work'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removed subject 01, 11, 15, subject 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [\n",
    "    'sub-002', 'sub-003', 'sub-004', 'sub-005','sub-006','sub-007','sub-008','sub-009','sub-010',\n",
    "    'sub-011','sub-012','sub-013','sub-014','sub-016','sub-017','sub-018','sub-019','sub-020','sub-021',\n",
    "    'sub-022','sub-023','sub-024','sub-025','sub-026','sub-027','sub-028','sub-029','sub-030','sub-031','sub-032',\n",
    "    'sub-033','sub-034','sub-035','sub-036','sub-037','sub-038','sub-039','sub-040'\n",
    "]\n",
    "\n",
    "sub_list = [\n",
    "    'sub-002', 'sub-003', 'sub-004', 'sub-005','sub-006','sub-007','sub-008','sub-009','sub-010',\n",
    "    'sub-012','sub-013','sub-014','sub-016','sub-017','sub-018','sub-019','sub-020','sub-021',\n",
    "    'sub-022','sub-023','sub-024','sub-025','sub-026','sub-027','sub-028','sub-029','sub-030','sub-031',\n",
    "    'sub-033','sub-034','sub-035','sub-036','sub-037','sub-038','sub-039','sub-040'\n",
    "]\n",
    "sub_list = ['sub-015']\n",
    "tot_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes:\\n- Do not deal with subject confounds here\\n- need to write code that will grab the confounds for the SEVENTH run\\nsub-012: NO CONFOUNDS FOR RUN 5 -- OUTPUT RUN 6 AND RUN 7 BUT NO RUN 5\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notes:\n",
    "- Do not deal with subject confounds here\n",
    "- need to write code that will grab the confounds for the SEVENTH run\n",
    "sub-012: NO CONFOUNDS FOR RUN 5 -- OUTPUT RUN 6 AND RUN 7 BUT NO RUN 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled confound models for sub-015\n",
      "Assembled confound models for sub-015\n",
      "Assembled confound models for sub-015\n",
      "Assembled confound models for sub-015\n",
      "Assembled confound models for sub-015\n"
     ]
    }
   ],
   "source": [
    "# check runs\n",
    "for sub in sub_list:\n",
    "    for run in range(1,tot_runs+1):\n",
    "        if sub == 'sub-012' and run >=5: run+=1\n",
    "        # run name\n",
    "        file1 = f'{sub}/ses-01/func/%s_ses-01_task-None_run-{run:02d}_desc-confounds_timeseries' % (sub)\n",
    "        #confounds_fn = os.path.join(fmri_prep, sub + \"/ses-01/func\",\"%s_ses-01_task-None_run-%s_desc-confounds_timeseries\" % (sub, run))\n",
    "        confounds_fn =  os.path.join(fmri_prep, file1)      # Set file for saving\n",
    "        out_name = 'confs'\n",
    "        out_dir = join(work_dir, out_name)\n",
    "\n",
    "        model =  {'confounds':\n",
    "                  ['trans_x', 'trans_y', 'trans_z',\n",
    "                   'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "                  'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                               {'n_comps': 5, 'tissue': 'WM'}]}\n",
    "\n",
    "\n",
    "        # Make directory if it doesn't exist\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "\n",
    "        # Loop through confound files (in case of multiple runs)\n",
    "        #for confounds_fn in confounds_fns:\n",
    "        confounds_df, confounds_meta = load_confounds(confounds_fn)\n",
    "\n",
    "        # Extract confounds based on model\n",
    "        confounds = extract_confounds(confounds_df,\n",
    "                                      confounds_meta,\n",
    "                                      model)\n",
    "        \n",
    "        \n",
    "        # Also create CSVs with headers for convenience\n",
    "        ort_csv = splitext(basename(confounds_fn).replace(\n",
    "            'desc-confounds',\n",
    "            f'desc-model'))[0] + '.csv'\n",
    "        ort_fn = join(out_dir, ort_csv)\n",
    "        #### save confound file !\n",
    "        confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "\n",
    "        print(f\"Assembled confound models for {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{run:02d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for anomaly subs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled confound models for sub-029\n"
     ]
    }
   ],
   "source": [
    "# seven runs for these subjects\n",
    "for sub in ['sub-029']:\n",
    "    for run in range(7,8):\n",
    "        # run name\n",
    "        file1 = f'{sub}/ses-01/func/%s_ses-01_task-None_run-{run:02d}_desc-confounds_timeseries' % (sub)\n",
    "        #confounds_fn = os.path.join(fmri_prep, sub + \"/ses-01/func\",\"%s_ses-01_task-None_run-%s_desc-confounds_timeseries\" % (sub, run))\n",
    "        confounds_fn =  os.path.join(fmri_prep, file1)      # Set file for saving\n",
    "        \n",
    "        # Set file for saving\n",
    "        out_name = 'confs'\n",
    "        out_dir = join(work_dir, out_name)\n",
    "\n",
    "        model =  {'confounds':\n",
    "                  ['trans_x', 'trans_y', 'trans_z',\n",
    "                   'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "                  'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                               {'n_comps': 5, 'tissue': 'WM'}]}\n",
    "\n",
    "\n",
    "        # Make directory if it doesn't exist\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "\n",
    "        # Loop through confound files (in case of multiple runs)\n",
    "        #for confounds_fn in confounds_fns:\n",
    "        confounds_df, confounds_meta = load_confounds(confounds_fn)\n",
    "\n",
    "        # Extract confounds based on model\n",
    "        confounds = extract_confounds(confounds_df,\n",
    "                                      confounds_meta,\n",
    "                                      model)\n",
    "        \n",
    "        \n",
    "        # Also create CSVs with headers for convenience\n",
    "        ort_csv = splitext(basename(confounds_fn).replace(\n",
    "            'desc-confounds',\n",
    "            f'desc-model'))[0] + '.csv'\n",
    "        ort_fn = join(out_dir, ort_csv)\n",
    "        #### save confound file !\n",
    "        #confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "\n",
    "        print(f\"Assembled confound models for {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub 032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SUB-032:\n",
    "- grab the first run for session 1\n",
    "- for runs after run 2, grab the second session\n",
    "- subtract one run to match the run output, which is 1-5 here\n",
    "- save the runs +1 so session two is equivalen to 2-6 instead of 1-5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled confound models for sub-032\n",
      "Assembled confound models for sub-032\n",
      "Assembled confound models for sub-032\n",
      "Assembled confound models for sub-032\n",
      "Assembled confound models for sub-032\n",
      "Assembled confound models for sub-032\n"
     ]
    }
   ],
   "source": [
    "### SUBJECT 032 -- save each session 02 as run +1 ## \n",
    "\n",
    "for sub in ['sub-032']:\n",
    "    for run in range(1,7):\n",
    "        # run name\n",
    "        if run < 2:\n",
    "            file1 = f'{sub}/ses-01/func/%s_ses-01_task-None_run-{run:02d}_desc-confounds_timeseries' % (sub)\n",
    "        else:\n",
    "            run_adjust = run -1 \n",
    "            file1 = f'{sub}/ses-02/func/%s_ses-02_task-None_run-{run_adjust:02d}_desc-confounds_timeseries' % (sub)\n",
    "        confounds_fn =  os.path.join(fmri_prep, file1)      # Set file for saving\n",
    "        \n",
    "        # Set file for saving\n",
    "        out_name = 'confs'\n",
    "        out_dir = join(work_dir, out_name)\n",
    "\n",
    "        model =  {'confounds':\n",
    "                  ['trans_x', 'trans_y', 'trans_z',\n",
    "                   'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "                  'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                               {'n_comps': 5, 'tissue': 'WM'}]}\n",
    "\n",
    "\n",
    "        # Make directory if it doesn't exist\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "\n",
    "        # Loop through confound files (in case of multiple runs)\n",
    "        #for confounds_fn in confounds_fns:\n",
    "        confounds_df, confounds_meta = load_confounds(confounds_fn)\n",
    "\n",
    "        # Extract confounds based on model\n",
    "        confounds = extract_confounds(confounds_df,\n",
    "                                      confounds_meta,\n",
    "                                      model)\n",
    "        \n",
    "        \n",
    "        # Also create CSVs with headers for convenience\n",
    "        ## save each session 02 as run +1\n",
    "        if run < 2:\n",
    "            ort_csv = splitext(basename(confounds_fn).replace(\n",
    "                'desc-confounds',\n",
    "                f'desc-model'))[0] + '.csv'\n",
    "            ort_fn = join(out_dir, ort_csv)\n",
    "            #### save confound file !\n",
    "            confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "        else:\n",
    "            ort_csv = splitext(basename(confounds_fn).replace(\n",
    "                f'{run_adjust:02d}_desc-confounds',\n",
    "                f'{run:02d}_desc-model'))[0] + '.csv'\n",
    "            ort_fn = join(out_dir, ort_csv)\n",
    "            #### save confound file !\n",
    "            confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "\n",
    "        print(f\"Assembled confound models for {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub-015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check runs\n",
    "for sub in ['sub-015']:\n",
    "    for run in range(1,tot_runs+1):\n",
    "        if sub == 'sub-012' and run >=5: run+=1\n",
    "        # run name\n",
    "        file1 = f'{sub}/ses-01/func/%s_ses-01_task-None_run-{run:02d}_desc-confounds_timeseries' % (sub)\n",
    "        #confounds_fn = os.path.join(fmri_prep, sub + \"/ses-01/func\",\"%s_ses-01_task-None_run-%s_desc-confounds_timeseries\" % (sub, run))\n",
    "        confounds_fn =  os.path.join(fmri_prep, file1)      # Set file for saving\n",
    "        out_name = 'confs'\n",
    "        out_dir = join(work_dir, out_name)\n",
    "\n",
    "        model =  {'confounds':\n",
    "                  ['trans_x', 'trans_y', 'trans_z',\n",
    "                   'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "                  'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                               {'n_comps': 5, 'tissue': 'WM'}]}\n",
    "\n",
    "\n",
    "        # Make directory if it doesn't exist\n",
    "        if not exists(out_dir):\n",
    "            makedirs(out_dir)\n",
    "\n",
    "        # Loop through confound files (in case of multiple runs)\n",
    "        #for confounds_fn in confounds_fns:\n",
    "        confounds_df, confounds_meta = load_confounds(confounds_fn)\n",
    "\n",
    "        # Extract confounds based on model\n",
    "        confounds = extract_confounds(confounds_df,\n",
    "                                      confounds_meta,\n",
    "                                      model)\n",
    "        \n",
    "        \n",
    "        # Also create CSVs with headers for convenience\n",
    "        ort_csv = splitext(basename(confounds_fn).replace(\n",
    "            'desc-confounds',\n",
    "            f'desc-model'))[0] + '.csv'\n",
    "        ort_fn = join(out_dir, ort_csv)\n",
    "        #### save confound file !\n",
    "        #confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "\n",
    "        print(f\"Assembled confound models for {sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub-032_ses-02_task-None_run-06_desc-model_timeseries.csv'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z', 'cosine00',\n",
       "       'cosine01', 'cosine02', 'cosine03', 'cosine04', 'cosine05', 'cosine06',\n",
       "       'cosine07', 'a_comp_cor_00', 'a_comp_cor_01', 'a_comp_cor_02',\n",
       "       'a_comp_cor_03', 'a_comp_cor_04', 'a_comp_cor_11', 'a_comp_cor_12',\n",
       "       'a_comp_cor_13', 'a_comp_cor_14', 'a_comp_cor_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confounds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  {'confounds':\n",
    "          ['trans_x', 'trans_y', 'trans_z',\n",
    "           'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "          'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                       {'n_comps': 5, 'tissue': 'WM'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confounds': ['trans_x',\n",
       "  'trans_y',\n",
       "  'trans_z',\n",
       "  'rot_x',\n",
       "  'rot_y',\n",
       "  'rot_z',\n",
       "  'cosine'],\n",
       " 'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'}, {'n_comps': 5, 'tissue': 'WM'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled confound models for sub-012\n",
      "Assembled confound models for sub-012\n",
      "Assembled confound models for sub-012\n",
      "Assembled confound models for sub-012\n",
      "Warning: Only 2 aCompCor components available (5 requested)\n",
      "Warning: Only 2 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-012\n",
      "Assembled confound models for sub-012\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-013\n",
      "Assembled confound models for sub-014\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-014\n",
      "Assembled confound models for sub-014\n",
      "Assembled confound models for sub-014\n",
      "Assembled confound models for sub-014\n",
      "Assembled confound models for sub-014\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-016\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-017\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-018\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-019\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-020\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-021\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-022\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-023\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-024\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-026\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-027\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-029\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-030\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-031\n",
      "Assembled confound models for sub-033\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-033\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-033\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-033\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-033\n",
      "Warning: Only 4 aCompCor components available (5 requested)\n",
      "Assembled confound models for sub-033\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-034\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-035\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-036\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-037\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-038\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-039\n",
      "Assembled confound models for sub-040\n",
      "Assembled confound models for sub-040\n",
      "Assembled confound models for sub-040\n",
      "Assembled confound models for sub-040\n",
      "Assembled confound models for sub-040\n",
      "Assembled confound models for sub-040\n"
     ]
    }
   ],
   "source": [
    "# afni\n",
    "\"\"\"\n",
    "for sub in sub_list:\n",
    "    for run in range(1,tot_runs+1):\n",
    "                \n",
    "        file1 = os.path.join(fmri_prep, sub + \"/ses-01/func\")\n",
    "        confounds_fn = os.path.join(fmri_prep, sub + \"/ses-01/func\",\"%s_ses-01_task-None_run-%s_desc-confounds_timeseries\" % (sub, run))\n",
    "\n",
    "        # Set an AFNI pipeline output directory (either -smooth or -nosmooth)\n",
    "        out_pipe = 'afni-head_mot'\n",
    "        afni_dir = join(work_dir, afni_pipe)\n",
    "\n",
    "        model =  {'confounds':\n",
    "                  ['trans_x', 'trans_y', 'trans_z',\n",
    "                   'rot_x', 'rot_y', 'rot_z', 'cosine'],\n",
    "                  'aCompCor': [{'n_comps': 5, 'tissue': 'CSF'},\n",
    "                               {'n_comps': 5, 'tissue': 'WM'}]}\n",
    "\n",
    "        # Loop through tasks and subjects and grab confound files\n",
    "\n",
    "        # Make directory if it doesn't exist\n",
    "        ort_dir = join(afni_dir, sub, 'func')\n",
    "        if not exists(ort_dir):\n",
    "            makedirs(ort_dir)\n",
    "\n",
    "        # Grab confound files for multiple runs if present\n",
    "        #confounds_fns = natsorted(\n",
    "        #    task_meta[task][subject]['confounds'])\n",
    "\n",
    "        # Loop through confound files (in case of multiple runs)\n",
    "        #for confounds_fn in confounds_fns:\n",
    "        confounds_df, confounds_meta = load_confounds(confounds_fn)\n",
    "\n",
    "        # Extract confounds based on model\n",
    "        confounds = extract_confounds(confounds_df,\n",
    "                                      confounds_meta,\n",
    "                                      model)\n",
    "        \n",
    "        # Create output 1D file for AFNI and save\n",
    "        ort_1d = splitext(basename(confounds_fn).replace(\n",
    "            'desc-confounds',\n",
    "            f'desc-model'))[0] + '.1D'\n",
    "        ort_fn = join(ort_dir, ort_1d)\n",
    "        #confounds.to_csv(ort_fn, sep='\\t', header=False,\n",
    "          #               index=False)\n",
    "        \n",
    "        # Also create CSVs with headers for convenience\n",
    "        ort_csv = splitext(basename(confounds_fn).replace(\n",
    "            'desc-confounds',\n",
    "            f'desc-model'))[0] + '.csv'\n",
    "        ort_fn = join(ort_dir, ort_csv)\n",
    "        #confounds.to_csv(ort_fn, sep=',', index=False)\n",
    "\n",
    "        print(f\"Assembled confound models for {sub}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
