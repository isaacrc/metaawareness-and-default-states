{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ready-development",
   "metadata": {},
   "source": [
    "# Preprocess fMRI data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-banks",
   "metadata": {},
   "source": [
    "This script further preprocesses fmriprep's preprocessed data. Options for preprocessing include smoothing, regressing confounds, high pass, low pass, and masking. Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-angel",
   "metadata": {},
   "source": [
    "## py conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "intelligent-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to python slurm_create-data_preproc.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-culture",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prime-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys  \n",
    "import random\n",
    "# import logging\n",
    "\n",
    "import deepdish as dd\n",
    "import numpy as np\n",
    "\n",
    "import brainiak.eventseg.event\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "# Import a function from BrainIAK to simulate fMRI data\n",
    "import brainiak.utils.fmrisim as sim  \n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, zscore, pearsonr\n",
    "from scipy.signal import gaussian, convolve\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "\n",
    "from brainiak import image, io\n",
    "from scipy.stats import stats\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img,index_img\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_to_img, concat_imgs\n",
    "\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img\n",
    "from nilearn.plotting import view_img\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import os.path\n",
    "import scipy.io\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.masking import compute_epi_mask, compute_brain_mask\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "editorial-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-communist",
   "metadata": {},
   "source": [
    "## custom helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complete-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_anal import load_epi_data, load_conf_data, load_epi_sub032, load_conf_sub032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "matched-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_isc(fmri_prep, sub, num_runs, space, fwhm, mask):\n",
    "    # This is based off of 'load_data' function in template\n",
    "    # Loads all fMRI runs into a NUMPY matrix #\n",
    "\n",
    "    \"\"\"\n",
    "    purpose: get a cleaned epi \n",
    "    inputs:\n",
    "        - fmri_prep: path\n",
    "        - morph = T1 or MNI registration?\n",
    "        - norm_type = by Space or by Time?\n",
    "    return: a dictionary of runs, preprocessed \n",
    "    \"\"\"\n",
    "    run_dic = {}\n",
    "    print(\"Begin preproc, u dynamic lil windmill!\")\n",
    "    ## preprocess 7 runs ## \n",
    "    for run in range(1, num_runs + 1):\n",
    "        ### subject specific loading ###  \n",
    "        if sub == 'sub-003' and run == 6:\n",
    "            ## load the seventh, instead of sixth run -- this is a quirk of this dataset ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "\n",
    "        elif sub == 'sub-012' and run >= 5:\n",
    "            print('ADJUSTING')\n",
    "            ## load the 6th, 7th run, instead of 5, 6 -- this is a quirk of this dataset ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "\n",
    "        elif sub == 'sub-032': \n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_sub032(conf_dir, sub, run) # scanned in two sessions\n",
    "            # Load EPI\n",
    "            epi = load_epi_sub032(fmri_prep, sub, run,space)\n",
    "        elif sub == 'sub-014' and run >=2: \n",
    "            ## skip the second run ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "        elif sub == 'sub-029' and run >=4: \n",
    "            ## do not use runs 3 + 4 -- this sub only has 5 usable runs ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "        elif sub == 'sub-015' and run >=5: \n",
    "            ## this sub only has 4 usable runs ##\n",
    "            continue\n",
    "        else:\n",
    "            #### Load the epi if regular sub or run ####\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, run,space)\n",
    "\n",
    "            print(f'run {run} shape: {epi.shape}')\n",
    "        \n",
    "        ### Regress confounds ### \n",
    "        # OPTIONS: low_pass= .1, high_pass=1/128, .01 might be more normal...\n",
    "        clean_bold = image.clean_img(epi, standardize = False, confounds = run_conf, high_pass=1/128,\n",
    "                           t_r=1.5, mask_img = mask)\n",
    "        \n",
    "        ### Blur Image (smooth) ##\n",
    "        smooth_bold = image.smooth_img(clean_bold, fwhm=fwhm)\n",
    "        ### Script options ### \n",
    "\n",
    "        #### Mask off baybee! as future would say, lol # \n",
    "        nifti_masker = NiftiMasker(mask_img=mask)\n",
    "        masked_data = nifti_masker.fit_transform(smooth_bold)\n",
    "        \n",
    "        ## adjust subject 2 to append two extra TRs to the end of shrek -- quirk of dataset ## \n",
    "        if run == 1 and sub == 'sub-002':\n",
    "            masked_data = np.vstack((masked_data, np.tile(masked_data[-1, :], (2, 1))))\n",
    "        \n",
    "        #### Save Date \n",
    "        run_dic[run] = masked_data\n",
    "        print(f'finished run {run}')\n",
    "    print(\"FINISHED YAY BEAST\")\n",
    "    return run_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "intense-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_isc_imgs(fmri_prep, sub, num_runs, space, fwhm, mask):\n",
    "    # This is based off of 'load_data' function in template\n",
    "    # Loads all fMRI runs into a 4D NIFTI list #\n",
    "    \"\"\"\n",
    "    purpose: get a cleaned epi \n",
    "    inputs:\n",
    "        - fmri_prep: path\n",
    "        - morph = T1 or MNI registration?\n",
    "        - norm_type = by Space or by Time?\n",
    "    return: a dictionary of runs, preprocessed \n",
    "    \"\"\"\n",
    "    run_dic = {}\n",
    "    print(\"Begin preproc, u dynamic lil windmill!\")\n",
    "    ## preprocess 7 runs ## \n",
    "    for run in range(1, num_runs + 1):\n",
    "        ### subject specific loading ###  \n",
    "        if sub == 'sub-003' and run == 6:\n",
    "            ## load the seventh, instead of sixth run -- this is a quirk of this dataset ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "\n",
    "        elif sub == 'sub-012' and run >= 5:\n",
    "            print('ADJUSTING')\n",
    "            ## load the 6th, 7th run, instead of 5, 6 -- this is a quirk of this dataset ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "\n",
    "        elif sub == 'sub-032': \n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_sub032(conf_dir, sub, run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_sub032(fmri_prep, sub, run,space)\n",
    "        elif sub == 'sub-014' and run >=2: \n",
    "            ## skip the second run ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "        elif sub == 'sub-029' and run >=4: \n",
    "            ## do not use runs 3 + 4 -- this sub only has 5 usable runs ##\n",
    "            adjust_run = run + 1\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, adjust_run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, adjust_run, space)\n",
    "        elif sub == 'sub-015' and run >=5: \n",
    "            ## this sub only has 4 usable runs ##\n",
    "            continue\n",
    "        else:\n",
    "            #### Load the epi if regular sub or run ####\n",
    "            # Load Confounds\n",
    "            run_conf = load_conf_data(conf_dir, sub, run)\n",
    "            # Load EPI\n",
    "            epi = load_epi_data(fmri_prep, sub, run,space)\n",
    "\n",
    "            print(f'run {run} shape: {epi.shape}')\n",
    "        \n",
    "        ### Regress confounds ### \n",
    "        # OPTIONS: low_pass= .1, high_pass=1/128, .01 might be more normal...\n",
    "        clean_bold = image.clean_img(epi, standardize = False, confounds = run_conf, high_pass=1/128,\n",
    "                           t_r=1.5, mask_img = mask)\n",
    "        \n",
    "        ### Blur Image (smooth) ##\n",
    "        smooth_bold = image.smooth_img(clean_bold, fwhm=fwhm)\n",
    "        ### Script options ### \n",
    "\n",
    "        #### Mask off baybee! as future would say, lol # \n",
    "        #nifti_masker = NiftiMasker(mask_img=mask)\n",
    "        #masked_data = nifti_masker.fit_transform(smooth_bold)\n",
    "        \n",
    "        ## adjust subject 2 to append two extra TRs to the end of shrek -- quirk of dataset ## \n",
    "        if run == 1 and sub == 'sub-002':\n",
    "            len_b = smooth_bold.shape[3]\n",
    "            print(len_b)\n",
    "            two_imgs = image.concat_imgs([index_img(smooth_bold, 1)]*2)\n",
    "            print(two_imgs.shape)\n",
    "            smooth_bold = image.concat_imgs([smooth_bold, two_imgs])\n",
    "            print(f'ADJUSTED: {smooth_bold.shape}')\n",
    "        \n",
    "        #### Save Date \n",
    "        run_dic[run] = smooth_bold\n",
    "        print(f'finished run {run}')\n",
    "    print(\"FINISHED YAY BEAST\")\n",
    "    return run_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-photographer",
   "metadata": {},
   "source": [
    "## directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "analyzed-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/jukebox/graziano/coolCatIsaac/MEI'\n",
    "data_dir = top_dir + \"/data\"\n",
    "work_dir = data_dir + '/work'\n",
    "mask_dir = work_dir + '/masks'\n",
    "behav_dir = top_dir + '/data/behavioral'\n",
    "rois_dir = data_dir + \"/rois\"\n",
    "fmri_prep = data_dir + '/bids/derivatives/fmriprep' ### DOWNLOAD FMRI DATA HERE\n",
    "conf_dir = work_dir + '/confs'\n",
    "preproc_dir = work_dir + '/preproc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-queue",
   "metadata": {},
   "source": [
    "## main vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "distinct-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sub_list ###\n",
    "sub_list = [\n",
    "    'sub-002', 'sub-003', 'sub-004', 'sub-005','sub-006','sub-007','sub-008','sub-009','sub-010',\n",
    "    'sub-012','sub-013','sub-014','sub-016','sub-017','sub-018','sub-019','sub-020','sub-021',\n",
    "    'sub-022','sub-023','sub-024','sub-025','sub-026','sub-027','sub-028','sub-029','sub-030','sub-031','sub-032',\n",
    "    'sub-033','sub-034','sub-035','sub-036','sub-037','sub-038','sub-039','sub-040', 'sub-041'\n",
    "]\n",
    "\n",
    "## current sublist does not include subject 011, subject 015, 001\n",
    "\n",
    "###### LOADING VARS #######\n",
    "# Number of runs to load \n",
    "num_runs = 6\n",
    "# Registration ust be either T1 or MNI\n",
    "space = \"MNI\"# \n",
    "\n",
    "## mask image ##\n",
    "mask_img = nib.load(mask_dir + \"/whole_b_bnk.nii.gz\")\n",
    "\n",
    "## FWHM smoothing factor ## \n",
    "fwhm = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "backed-motel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin preproc, u dynamic lil windmill!\n",
      "run: sub-041_ses-01_task-None_run-01_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 1 is (78, 93, 65, 397) \n",
      "\n",
      "run 1 shape: (78, 93, 65, 397)\n",
      "finished run 1\n",
      "run: sub-041_ses-01_task-None_run-02_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-02_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 2 is (78, 93, 65, 361) \n",
      "\n",
      "run 2 shape: (78, 93, 65, 361)\n",
      "finished run 2\n",
      "run: sub-041_ses-01_task-None_run-03_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-03_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 3 is (78, 93, 65, 429) \n",
      "\n",
      "run 3 shape: (78, 93, 65, 429)\n",
      "finished run 3\n",
      "run: sub-041_ses-01_task-None_run-04_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-04_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 4 is (78, 93, 65, 448) \n",
      "\n",
      "run 4 shape: (78, 93, 65, 448)\n",
      "finished run 4\n",
      "run: sub-041_ses-01_task-None_run-05_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-05_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 5 is (78, 93, 65, 389) \n",
      "\n",
      "run 5 shape: (78, 93, 65, 389)\n",
      "finished run 5\n",
      "run: sub-041_ses-01_task-None_run-06_desc-model_timeseries.csv\n",
      "Loading data from /jukebox/graziano/coolCatIsaac/MEI/data/bids/derivatives/fmriprep/sub-041/ses-01/func/sub-041_ses-01_task-None_run-06_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n",
      "shape of run 6 is (78, 93, 65, 437) \n",
      "\n",
      "run 6 shape: (78, 93, 65, 437)\n",
      "finished run 6\n",
      "FINISHED YAY BEAST\n"
     ]
    }
   ],
   "source": [
    "for sub in sub_list:\n",
    "    sub_dic = preproc_isc_imgs(fmri_prep, sub, num_runs, space, fwhm, mask_img)\n",
    "    out_name = f'/{sub}_fwhm{fwhm}_conf_4D.npy'\n",
    "    np.save(preproc_dir + out_name, sub_dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-objective",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
